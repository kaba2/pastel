PointKdTree design notes
========================

[Parent]: pointkdtree.txt

Invariants
----------

 * Every point is contained in the bounding box of the kd-tree.
 
 * A point is listed in a leaf node if and only if it is contained in
 the bounding box of the leaf node.

How to use the data structure?
------------------------------

The data structure is traversed using cursors.
A cursor is a pointer-like object that points to a node of the
kd-tree. As always, this allows for the separation of the
data structure and the algorithms that use it.

Should you store points at all nodes or just leaf nodes?
--------------------------------------------------------

### Proposition 1: Store one point at each split node

Advantages:

 * No additional memory management needed for points.

Disadvantages:
 
 * Not possible to remove points.
 
### Proposition 2: Store multiple points at leaf nodes

Advantages:

 * Possible to remove points.

Disadvantages:

 * Additional memory management needed for points.

### Decision

Choose Proposition 2.

How to support different kinds of objects?
------------------------------------------

### Proposition 1: an object oriented interface

	:::cpp
	class PointKdTreeObject
	{
	public:
		virtual ~PointKdTreeObject()
		{
		}
		
		virtual real position(integer axis) const = 0;
	};

Disadvantages:

 * Performance losses because of dynamic binding
 
 * Data has to be wrapped to objects which inherit from PointKdTreeObject.

### Proposition 2: generic programming

Store arbitrary user objects and require to supply a functor that
gives projection to an axis given an object.

	:::cpp
	template <int N, typename Real, typename Object,
	typename ProjectionFunctor>
	class PointKdtree
	{
	//...
	};

Advantages:

 * Efficient for concrete types
 
 * Supports sharing of data (for example, store indices to a vertex buffer)
 
 * You can still use polymorphic objects (for example Object = PointKdTreeObject*)
 
Disadvantages:

 * A bit too many template parameters

### Proposition 3: generic programming with a policy

	:::cpp
	template <typename Real, int N, typename ObjectPolicy>
	class PointKdTree
	{
	};

	class ObjectPolicy
	{
	public:
		typedef int Object;
		
		real position(const Object& object, integer axis) const;
	};

Advantages:

 * Efficient for concrete types
 
 * Supports sharing of data (for example, store indices to a vertex buffer)
 
 * You can still use polymorphic objects (for example Object = PointKdTreeObject*)

### Decision

Choose Proposition 3.

Interface for adding points to the tree
---------------------------------------

### Proposition 1: Give the PointKdTree a cursor and a point to add to that node

The problem with this approach is that the point might not be contained in the node
that the cursor is pointing to. This would in turn break our invariant.
Also, containment can't be checked without traversing the tree
from top to bottom because nodes do not store node bounds for all dimensions.

### Proposition 2: Give the PointKdTree a point to add to the tree

The tree is then traversed from top to bottom searching for the correct leaf
node to add the point to. Sounds good, however, if there are n points, then
the traversals for each point take extra time which could probably be
amortized by adding a set of points at the same time.

### Proposition 3: Give the PointKdTree a set of points to add to the tree

At each node, the set of points is partitioned into two sets, which are
sent down the node hierarchy. This way the traversal cost is amortized among
the set of added points.

### Decision

Choose Proposition 3.

How to store the objects of a leaf node?
----------------------------------------

### Proposition 1: An array or a linked list for each node

Advantages:

 * Incremental adding or removing of points
 possible, and reasonably efficient.

Disadvantages:

 * Each node requires dynamical allocation
 of a small memory region. This might
 waste more memory than needs to be.
 
 * It is not easy to access all objects of
 the tree as a sequence.
 
### Proposition 2: An array shared by all nodes

Leaf nodes would refer to objects in this
array by integer intervals.

Advantages:

 * One big memory allocation instead of many
 small ones.
 
 * Random-access to (permuted) object list is possible.
 
 * It is possible to hide/unhide points as per
 semidynamic point sets.
 
 * Fast because of good locality of reference.
 
Disadvantages:

 * Incremental adding or removing of points is not 
 possible because the integer intervals in the nodes 
 would be invalidated.
 
 * When hiding a point, the point must be kept
 in the tree's object list. I.e. while the point
 is hidden in the leaf node's object list, it is not 
 hidden in the tree's object list.

### Proposition 3: A linked list shared by all nodes

Leaf nodes would refer to objects in this list
by inclusive iterator intervals. Why inclusive intervals? 
Because the object that is pointed to by an end-iterator
of a normal range can get removed.

Advantages:

 * Sequential access to (permuted) object list possible.
 
 * It is possible to hide/unhide points as per
 semidynamic point sets.
 
 * When hiding, the points can actually be removed
 from the tree's object list.
 
 * It is possible to incrementally add or remove points
 and do this fast (if one also has bucket pointers).

Disadvantages:

 * No random access to object list.
 
 * Dynamic allocation for each linked list node, and
 traversal of the object list by following links might 
 not be so efficient.
 
### Decision

Random access to the object list is
important when parallelizing work that is to be done for
each point in the object list (or more properly, for each 
object iterator in the tree). If one chooses the linked
list approach, one can get around this problem by
copying the iterators of the object list to a random 
access array and then using that to carry out the task.
One does not have this problem with an array since it
already is random-access. However, this advantage of arrays
is diminished when considering semidynamic point sets:
if most of the points have been hided, then one
still has to visit those hided points in the object list.
Particularly because of this reason, Proposition 3 is chosen.

The importance of dividing equal points evenly
----------------------------------------------

Consider that there are n points and that they are all at
the same position. If you divide the points to child nodes
based purely on location (e.g. always store the a point on
the splitting plane to the negative child), then these 
positions necessarily end up at the same leaf node. Furthermore, 
if n exceeds the splitting threshold for a node, the leaf node 
is the result of splitting until the depth threshold is reached.

This example underlines the importance of distributing the
points on the splitting plane evenly to both
sides of the plane. When this is done, the number of points
at the same position diminishes exponentially. Thus,
for our example the height of the tree will be O(log n).

In combination with the sliding midpoint rule, which guarantees
that at least 1 point is separated from the others at each
split, distributing equal points evenly guarantees that the number 
of nodes is O(n) in the worst case.

Removal of points
-----------------

The removal of points requires an efficient way to find out
for each point (its iterator) the leaf node that it is stored in.

### Proposition 1: Do not allow removal of points

This is the only choice if one decides to store the
objects in an array.

### Proposition 2: Search the tree for the containing leaf node

This approach does not work, because one does not know which
node to follow in the case of a point exactly on the splitting
plane.

### Proposition 3: Store with each point its containing leaf node

Advantages:

 * Constant complexity performance for finding the leaf node.
 
 * Allows for very fast bottom-top nearest neighbors
 searches.
 
Disadvantages:

 * Increased memory requirements
 
### Decision

Choose Proposition 3. The increased memory requirement 
is of no concern. When a lot of objects need to be removed, 
it would be useful to have a  function that removes all objects, 
but leaves the subdivision structure intact.

How should you deal with changing geometry?
-------------------------------------------

Because you can actually be holding only references to the geometry data,
it is possible for the user to change geometry without the kd-tree
knowing about it. The end-result is that one can invalidate both invariants 
of the kdtree by modifying point locations. We have no way to prevent this
except for the documentation. This problem is similar to what happens
with the std::set (for example) if one uses pointers as keys and 
compares them by their values. We can only educate the user that whenever 
he wishes to change geometry, he should do it by removing, changing, and 
inserting back.

### Decision

Document that the user should not change geometry, but instead follow the
remove-change-insert pattern. 

How should you store the nodes?
-------------------------------

### Proposition 1: Store nodes in an array

 * At times the array memory will be reallocated
 
 * Therefore indices must be used as child references
 
 * But this increases indirection in node traversal
 
 * It can be problematic if the reallocation happens in the middle
 of a recursive function call (subdivision) invalidating node pointers at
 previous levels. Practically, this means that this
 technique does not work.

### Proposition 2: Allocate each node dynamically

You can avoid allocation overhead by using a PoolAllocator or 
ArenaAllocator.

### Decision

Choose Proposition 2 as the only working one.

Null references to children
---------------------------

If there are no objects in a child of a split node, 
you can either create an empty leaf node or give a null reference to
the intermediate node. However, empty leaf nodes are helpful when you 
want to subdivide, because then you can explicitly point to the node
you want to subdivide. With null references you have to be indirect 
from the parent: "subdivide the negative child of this node". This
is very impractical.

### Decision

A splitting node always refers to two concrete children.

Should the kd-tree know its bounding box?
-----------------------------------------

The bounding box of the kd-tree (or its contained box) is often
needed. Tracing the bounding box is easily done when adding
points to the tree. In contrast, if the bounding box wasn't
traced, then it would have to be recomputed manually and this
can mean that it can be done many times redundantly.

If the bounding box is traced, then it would be useful to have
a function to enlarge it (but not shrink it).

### Decision

Trace the bounding box of the tree when adding points. Make it 
possible to enlarge the bounding box but not shrink it.

Should the nodes know their parent nodes?
-----------------------------------------

If one adds the ability to find the leaf node of an object
directly, as is discussed in the removal of points,
then by adding parent nodes one makes it possible to
implement a very efficient bottom-top nearest neighbor
searching. But parent nodes also make it possible to turn
the kdtree into a self-adapting tree under removal and addition
of points. 

### Semi-adaptation by knowing that a subtree is empty

Jon Bentley writes on the paper "Semidynamic point sets for kdtrees" 
about such a structure. To each node he adds the information whether 
the subtree under it is empty (void of points) or not. When all the 
points of a leaf node are removed, this information is propagated up
using the parent links. Then, when searching nearest neighbors,
for example, he skips those subtrees which are empty
without needing to inspect them. It is as if the
tree adapted to the new distribution of points after
removal, although there are no changes to the structure itself.

### Adaptation by knowing the number of points under a subtree

The previous idea can be generalized considerably. Rather than
at each node knowing if the subtree under it is empty or not,
one stores the number of points under that subtree.
This can of course be used in exactly the same way
as with the previous idea. However, we can do much better
with this increased amount of information:

After removing points in a leaf node, sum the 
number of points under the node with the number of points under
its sibling node. If this number is below the splitting threshold,
merge the nodes, making their parent node a leaf node.
Recurse this scheme up as long as possible using the parent links.

This results in graceful degradation when _removing points_.
However, if we were to remove points only temporally, and
insert them back later, we would have to refine the structure 
because the structure was simplified in the meantime.

### Semi-adaptation

There is a difference in the adaptation styles of the
empty-subtree and count-subtree approaches just described.
While the latter adaptation worked by modifying the tree structure,
the former adaptation worked by providing additional information 
at a rougher level of detail. Let us call this semi-adaptation.

In some cases it would be useful to have a semi-adapting style.
In particular, the following is an important use-case.
The user creates a kd-tree from a sequence of points that are
indexed by time, and refines the tree to get a good subdivision. 
He then removes all the points from the tree, but leaves the 
subdivision intact. Next he starts sliding a time-window in the 
sequence of points, such that at each time instant it holds that
the points in the tree are exactly those inside the time-window.
Of course, the hope is that the points, considered all at once,
would induce a good subdivision for all time instants, when combined
with semi-adaptation. Compare this with the alternative approach
of reconstructing the tree from scratch at each time instant.

### Semi-adaptation by knowing the points under a subtree (and their number)

The approach of counting the number of points under a subtree 
can be made semi-adapting by adding yet more information.
First, each node must know the set of points under its subtree
(i.e. every node must be able to present the information of a 
leaf node). By ordering the points in the point list in a proper way, this 
set can be given, for each node, simply by an iterator range. 
This way the tree can be looked at from different levels of
detail, resulting in semi-adaptation. Second, we note that 
if the objects are given a direct link to their containing leaf 
nodes, then while the tree semi-adapts, these links still point 
to the bottom of the tree, making bottom-up searches slow. This 
can be remedied by storing to each leaf node a 'bucket node' link. 
This link points to that node which contains the points of the 
leaf node, and whose parent would contain more than the splitting 
threshold number of points.

### Cost of hierarchical information

There is some cost in updating hierarchical information. For example, 
the removal of a point needs to traverse from the leaf node to the root 
while updating the hierarhical information. There are also the increased 
memory requirements.

### Decision

Provide each node with a parent pointer, an iterator range
for the points under its subtree, and the number of points
under its subtree. This allows for a semi-adapting tree 
(as well as an adapting tree). 

Should you use the same data structure for points and arbitrary shapes?
-----------------------------------------------------------------------

This is possible. However:

 * The shapes have to be abstracted by their bounding aligned boxes.
 Point based implementations then suffer abstraction penalty.

 * The splitting bounds and parent nodes are needed by nearest neighbor
 searching with points but are not needed in ray tracing.
 Ray tracing then suffers abstraction penalty.
 
 * Nearest neighbor searching does not make sense for general shapes.
 Or it does but would be hard to implement.

### Decision

Because of the abstraction penalties in both directions, a better 
alternative is to separately create a kd-tree that is designed 
for point sets (PointKdTree) and a kd-tree that is designed for ray 
tracing (KdTree)

What information do you need in nodes?
--------------------------------------

Both nodes:

 * pointer to parent node
 
 * a bit to differentiate between
 a leaf node and a split node
 
 * a bit to denote if the subtree below
 the node is empty or not

Leaf node:

 * element count
 
 * interval in the object list

Split node:

 * pointers to child nodes
 
 * splitting position
 
 * splitting axis
 
 * node bounds on the splitting axis

Enumerations of different kinds of kdtrees
------------------------------------------

### Basic version

Description:

 * Split nodes know their bounds on splitting axis
 
 * Leaf nodes know their set of points and their number
 
Advantages:

 * Minimal memory use.
 
 * Good enough to implement high performance
 top-bottom algorithms.

Shortcomings:

 * Points can't be removed, except all at once.
 
 * No adaptation to smaller point sets (i.e.
 removing all points without touching the subdivision
 and inserting back a subset of those points).
 
 * Bottom-up algorithms are not possible.

### Removable version
 
Additional features to basic version:

 * For each point, store its containing leaf node.

Advantages compared to basic version:

 * Points can be removed. 

### Adaptable version

Additional features to removable version:

 * Parent node is stored for each node.

Advantages compared to removable version:

 * Bottom-up algorithms are possible.

 * The tree can be made adaptive and to
 efficiently update hierarchical information.

### Bentley's version

Additional features to adaptable version:

 * An empty-flag is stored for each node,
 denoting if the subtree under that node
 is void of points.
 
Comments:
 
 * The empty-flags are hierarchical information
 which are efficiently updated by using the
 parent links.

Advantages compared to adaptable version:

 * The empty-flag allows to skip examining
 empty parts of the tree. 
 
Shortcomings:

  * The adaptation is probably not that effective 
  in practice because it requires a wholly empty subtree
  before stepping into action.
  
  * Bottom-up algorithms still have to start at leaf nodes
  rather than from a more appropriate level of detail.

### Removal adaptation version

Additional features to adaptable version:

 * New invariant: a leaf node either is the root node,
 or the number of points under its parent is larger
 than the splitting threshold.
 
Comments:

 * The invariant can be kept satisfied by updating
 the tree structure at removal. After removing points
 from a leaf node the following happens.
 If the sibling node is not a leaf node, then it
 must be contain more than the splitting threshold
 number of points, as per the invariant, and nothing
 is done. Otherwise, one checks the sum of the number 
 of points in the current leaf node and its sibling. 
 If this is less than the splitting threshold, one merges 
 them into a common leaf node and recurses.
 
Advantages to adaptable version:

 * Adapts gracefully to removal of points.

Shortcomings:

 * In case the removal is just temporary, the adaptation
 destroys structure which needs to be refined again at insertion. 
 In this case it would be better that the structure would 
 be preserved, and adaptation would be achieved by some 
 book-keeping techique instead.

### Multi-resolution version

Additional features to adaptable version:

 * Every node knows the set of points and their number
 under its subtree.
 
Comments:
 
 * The points can be ordered in such a way that
 for each node the set of points can be given by an 
 iterator interval.

 * The set of points and their number are hierarchical 
 information which are efficiently updated by using the
 parent links.
 
 * When removing points from a leaf node, one does the following to
 update the set of objects and their numbers at nodes.
 The 'begin' iterator is set to the 'begin' iterator of the
 negative child. The 'last' iterator is set to the 'last' iterator
 of the positive child. The number of points is set to the sum
 of the number of points in negative and positive child.
 This has to be recursed all the way to the root.
 
 * When inserting points you can add the number of points
 in the nodes at the same time you propagate the points
 down. After reaching a leaf node you then only need to 
 update the 'begin' and 'last' iterators upwards which
 is more efficient than before. First take a 'negative-up' traversal. 
 If when following a parent link you came from the negative child, then
 update the 'begin' point iterator to the same as the negative child 
 and recurse. Otherwise stop. Then take a 'positive-up' traversal, which
 is identical but checks if you came from the positive child and updates 
 the 'last' point iterator.
 
Advantages compared to adaptable version:

 * The tree can be viewed at different levels of detail.
 In particular, top-bottom traversal can handle the points
 in blocks of appropriate size, without needing to traverse
 to the bottom.

Shortcomings:

 * Bottom-up searches must start at a leaf node although
 that would not necessarily be the appropriate level of 
 detail. 

### Multi-resolution with bucket pointers version

Additional features to multiresolution version:

 * Bucket node pointer is stored for each leaf node.
 
 * New invariant: the bucket node corresponding to
 a leaf node is such a node that:
  
	1. It contains the leaf node in its subtree
	
	2. The number of points under its subtree is at
	most the maximum of the splitting threshold and
	the number of points in the leaf node.
	
	3. Its parent (if it exists) has greater than 
	splitting threshold number of points under its subtree.
 
Comments:

 * When removing points from a leaf node, one does the 
 following to update the bucket nodes. First find the new 
 bucket node for the leaf node. Note that you can start this
 search from the current bucket node. Then iterate through all 
 points under the new bucket node, setting the bucket node of
 their associated leaf nodes to the new bucket node. Note this 
 is much faster than recursing to the subtrees to find
 the leaf nodes. This is because the number of points is
 bounded by the splitting threshold. In contrast, 
 the subtrees can be of considerable size.
 
Advantages compared to multiresolution version:

 * Bottom-up searches can start at the appropriate
 level of detail, namely from the bucket node.
 
Shortcomings:

 * Increased memory usage.

### Decision

Choose the multi-resolution with bucket pointers version. 
The only practical disadvantage is the increased memory use. 
In this regard we just bite the bullet and notice that this
is the price to pay for getting those nice features.

Summary
-------

 * The data structure is traversed using cursors allowing to
 separate data structure and algorithms that use it.
 
 * Generic programming together with policy based design is 
 used to support different types of point objects (and point 
 references as well).
 
 * Points are added to the tree as sets, rather than
 one by one. This is more efficient.
 
 * The objects in the tree are stored in a linked list
 which is shared between leaf nodes. The leaf nodes 
 refer to this list by inclusive iterator intervals.
 
 * Objects can be added and removed freely.
 
 * Each point stores its containing leaf node to enable
 fast removal and fast bottom-up nearest neighbor searching.
 
 * Each leaf node stores the corresponding bucket node.
 
 * Each node is allocated dynamically.
 
 * Each node stores the number of points under its subtree.
 
 * Each node stores the set of points under its subtree
 using an iterator range (which implies that the points
 have to be ordered in an approriate manner).
 
 * The intent is that each node can be considered as
 a leaf node, but with differing levels of detail.
 
 * Each node stores its parent node. This enables
 hierarchical information.
 
 * Each split node refers to exactly two concrete nodes.
 
 * Do not use the same data structure for points and
 general shapes (e.g. ray tracing). Instead, create a specialized
 data structure for both needs.

Implementation experience
-------------------------

 * The packing of nodes induces some performance degradation.
 
 * Efficient approximate nearest neighbors requires to store
 intermediate node bounds in the split dimension.
 
 * Storing the node bounds in the split dimension implies
 that the user can't be allowed to subdivide a node through
 a cursor since the node bounds can not be found out
 efficiently. 
 
 * Instead, you implement a member function
 that refines the kd-tree with a user-defined splitting rule.
 This way you keep the kd-tree nodes having the correct
 node bounds.
 
 * In nearest neighbor searching and refinement, recursive 
 function calls are faster than iteration based on a stack.
 
 * In nearest neighbor searching, performance is enhanced
 by computing partial distances: whenever the distance
 computation exceeds the current culling distance, the
 computation can be aborted.
 
 * In nearest neighbor searching, performance is enhanced
 by computing with norm bijections rather than norms
 (for example, squared L2-norm).

Rejected ideas
==============

Bucket pointers
---------------

Assume we have adopted the scheme where each node stores the set 
of points under its subtree (as well as their number). Then it would
be nice to store to each point a link to that node which contains 
the point and whose parents contains more than splitting threshold 
number of points.